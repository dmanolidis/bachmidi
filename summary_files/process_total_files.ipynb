{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Notes\n",
    "### Import the notes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./notes_total.csv\", names=[\"note\", \"count\", \"title\"], sep=\";\")\n",
    "df.sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"note\").sum().sort_values(\"count\", ascending=False).reset_index()\n",
    "natural = grouped[\"note\"].isin(['A', 'B', 'C', 'D', 'E', 'F', 'G'])\n",
    "sharp = grouped[\"note\"].isin(['A#', 'B#', 'C#', 'D#', 'E#', 'F#', 'G#'])\n",
    "flat = grouped[\"note\"].isin(['Ab', 'Bb', 'Cb', 'Db', 'Eb', 'Fb', 'Gb'])\n",
    "rest = ~natural & ~sharp & ~flat\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,40))\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.bar(x=grouped[natural][\"note\"], height = grouped[natural][\"count\"])\n",
    "plt.title('Natural Notes')\n",
    "\n",
    "plt.subplot(412)\n",
    "plt.bar(x=grouped[sharp][\"note\"], height = grouped[sharp][\"count\"])\n",
    "plt.title('Sharp Notes')\n",
    "\n",
    "plt.subplot(413)\n",
    "plt.bar(x=grouped[flat][\"note\"], height = grouped[flat][\"count\"])\n",
    "plt.title('Flat Notes')\n",
    "\n",
    "plt.subplot(414)\n",
    "plt.bar(x=grouped[rest][\"note\"], height = grouped[rest][\"count\"])\n",
    "plt.title('Other Notes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Chords\n",
    "### Import the chords file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./chords_total.csv\", names=[\"comb\", \"count\", \"title\"], sep=\";\")\n",
    "df.sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by specific chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbcomb = df.groupby(\"comb\").sum()[\"count\"].sort_values(ascending=False).reset_index()\n",
    "gbcomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by n-chord\n",
    "\n",
    "Converting chords to their n-note set, assuming inversional equivalency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Notes dictionary for 2 octaves, so notes can appear in any permutation\n",
    "notes_dic = {'C': [1, 13], 'C#': [2, 14], 'D': [3, 15], 'D#': [4, 16], 'E': [5, 17], 'F': [6, 18], \n",
    "             'F#': [7, 19], 'G': [8, 20], 'G#': [9, 21], 'A': [10, 22], 'A#': [11, 23], \n",
    "             'B': [12, 24], 'Db': [2, 14], 'Eb': [4, 16], 'Gb': [7, 19], \n",
    "             'Ab': [9, 21], 'Bb': [11, 23], 'E#': [6, 18], 'B#': [1, 13], 'Fb': [5, 17], 'Cb': [12, 24],\n",
    "             'C##': [3, 15], 'F##': [8, 18], \"G##\": [10, 22], \"Bbb\": [10, 22]}\n",
    "\n",
    "# Dictionary with traditional names of some n-chords\n",
    "chord_dict = {'0': 'Unison or Single Note', '037': 'Minor Chord', '047': 'Major Chord', \n",
    "              '036': 'Dim Chord', '048': 'Aug Chord', '0368': 'Dom 7 Chord', '027': 'Sus Chord', \n",
    "              '026': \"It6 Chord\", '025': \"mm Chord\", '0247': 'Mu Chord', '0358': 'Min7 Chord', \n",
    "              '035': 'Blues Chord', '0158': 'Major 7 Chord', '0258': 'Half-dim 7 Chord',\n",
    "              '01': 'Min Second Interval', '02': 'Maj Second Interval', \n",
    "              '03': 'Min Third Interval', '04': 'Maj Third Interval', '05': 'Perfect Fourth Interval', \n",
    "              '06': 'Aug Fourth Interval', '07': 'Perfect Fifth Interval'}\n",
    "\n",
    "def num_chords(lst):\n",
    "    \n",
    "    # Convert to numbers. Skip null values\n",
    "    ls = []\n",
    "    for note in lst:\n",
    "        try:\n",
    "            ls.append(notes_dic[note])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Get all possible combinations. This gives all possible positions and inversions of a n-chord.\n",
    "    comb_list = list(itertools.product(*ls))\n",
    "    \n",
    "    # We need to obtain the more compact form of an n-chord, i.e. the order of notes that minimizes \n",
    "    # the sum of the distances of the notes.\n",
    "    if len(ls) > 1:\n",
    "\n",
    "        comb_array = np.array(comb_list)\n",
    "        diff = np.max(comb_array, axis=1) - np.min(comb_array, axis=1)\n",
    "        min_idxs = np.where(diff == diff.min())\n",
    "        min_arrays = comb_array[min_idxs]\n",
    "        min_arrays = np.sort(min_arrays, axis=1)\n",
    "\n",
    "        for i, min_array in enumerate(min_arrays):\n",
    "            min_arrays[i] = min_array - min_array[0]\n",
    "        fin_array = np.sort(min_arrays, axis=0)[0]\n",
    "\n",
    "        return tuple(fin_array)\n",
    "    else:\n",
    "        return tuple([0])\n",
    "\n",
    "\n",
    "def tryconvert(x):\n",
    "    try:\n",
    "        chord = chord_dict[x]\n",
    "    except:\n",
    "        chord = x\n",
    "    \n",
    "    return chord\n",
    "\n",
    "\n",
    "print(num_chords(['C', 'F', 'G']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbcomb[\"comb_list\"] = gbcomb[\"comb\"].apply(lambda x: x.split(\" \"))\n",
    "gbcomb[\"num_chords\"] = gbcomb[\"comb_list\"].apply(num_chords)\n",
    "gbcomb[\"text_num_chord\"] = gbcomb[\"num_chords\"].apply(lambda x: ''.join([str(ch) for ch in x]))\n",
    "gbcomb[\"chord\"] = gbcomb[\"text_num_chord\"].apply(tryconvert)\n",
    "\n",
    "grouped = gbcomb.groupby(\"chord\").sum()[\"count\"].sort_values(ascending=False).reset_index()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grouped = grouped.head(25).sort_values(\"count\")\n",
    "\n",
    "plt.figure(figsize=(20,80))\n",
    "plt.subplot(411)\n",
    "\n",
    "plt.barh(y=grouped[\"chord\"], width = grouped[\"count\"])\n",
    "plt.yticks(size=22)\n",
    "plt.title('Chord Frequency', size=26)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a curve to the data\n",
    "\n",
    "Fit a Hurwitz zeta function to the data, \n",
    "\n",
    "\\begin{equation*}\n",
    "f(k,q,s) = \\frac{C}{(k+q)^s}\n",
    "\\end{equation*}\n",
    "\n",
    "according to Zipfâ€“Mandelbrot law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return a /(x + b)**c\n",
    "\n",
    "\n",
    "xdata = np.arange(1, gbcomb.shape[0]+1)\n",
    "ydata = gbcomb[\"count\"]\n",
    "\n",
    "popt, pcov = curve_fit(func, xdata, ydata)\n",
    "gbcomb[\"fit\"] = func(xdata, *popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "line1 = ax.scatter(xdata, ydata, label='Frequency', c=\"tomato\", linewidth=1.5)\n",
    "ax.tick_params(direction=\"in\", which=\"both\")\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "line2 = ax.plot(xdata, gbcomb[\"fit\"], dashes=[3, 3, 10, 3], label='Fit', c=\"black\", linewidth=1.5)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Chord Progression\n",
    "### Import the files and merge them into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./strings_total.csv\", names=[\"title\", \"string\"], sep=\";\")\n",
    "df[\"num\"] = df.title.apply(lambda x: x.split(\"_\")[0][3:])\n",
    "\n",
    "keys = pd.read_csv(\"./keys.csv\", names=[\"num\", \"key\"], sep=\",\")\n",
    "df = df.merge(keys, on=\"num\")\n",
    "documents = df.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get chord progression from documents as n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "df[\"chors_list\"] = df.string.apply(lambda x: x.split(\" \"))\n",
    "\n",
    "# n can be adjusted to values other than 2\n",
    "df[\"bigrams\"] = df.chors_list.apply(lambda x: list(ngrams(x, 2)))\n",
    "\n",
    "biglist = df.bigrams.sum()\n",
    "biglist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Include only n-grams (chord progressions) having atleast one trichord or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = []\n",
    "for prog in biglist:\n",
    "    len_list = []\n",
    "    for chord in prog:\n",
    "        note_list = chord.strip().split(\"-\")\n",
    "        fin_len = len(note_list)\n",
    "        len_list.append(fin_len)\n",
    "    len_arr = np.array(len_list)\n",
    "    cond = np.all(len_arr > 0) and np.any(len_arr > 2)\n",
    "    if cond:\n",
    "        filtered.append(prog)\n",
    "\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chord conversion\n",
    "Convert chords to note sets and get the most used chord progressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_chord(string):\n",
    "    # Convert chords using num_chords function from section 2\n",
    "    ls = string.split(\"-\")\n",
    "    tup = num_chords(ls)\n",
    "    \n",
    "    return tup\n",
    "\n",
    "\n",
    "conv_prog_list = []\n",
    "for tup in filtered:\n",
    "    prog_list = []\n",
    "    for string in tup:\n",
    "        ls = convert_chord(string)\n",
    "        prog_list.append(ls)\n",
    "    conv_prog_list.append(tuple(prog_list))\n",
    "\n",
    "freq_prog = FreqDist(conv_prog_list).most_common()\n",
    "freq_prog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to traditional chord names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trad_conv_chord(x):\n",
    "    chord_list = []\n",
    "    for num_chord in x:\n",
    "        chord = tryconvert(num_chord)\n",
    "        chord_list.append(chord)\n",
    "    return chord_list\n",
    "\n",
    "df_prog = pd.DataFrame(freq_prog, columns=[\"Prog\", \"Freq\"])\n",
    "df_prog[\"num_chord\"] = df_prog[\"Prog\"].apply(lambda x: [''.join(str(ch) for ch in tup) for tup in x])\n",
    "\n",
    "df_prog[\"chord_name\"] = df_prog[\"num_chord\"].apply(trad_conv_chord)\n",
    "df_prog[\"chrd_prog\"] = df_prog[\"chord_name\"].apply(\" -> \".join)\n",
    "\n",
    "df_prog.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_prog.head(25).sort_values(\"Freq\")\n",
    "\n",
    "plt.figure(figsize=(20,80))\n",
    "plt.subplot(411)\n",
    "\n",
    "plt.barh(y=grouped[\"chrd_prog\"], width = grouped[\"Freq\"])\n",
    "plt.yticks(size=22)\n",
    "plt.title('Chord Frequency', size=26)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clusters\n",
    "### Train several models to determine the optimal k for k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, token_pattern=r\"(?u)\\S\\S+\", lowercase=False)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "sil = []\n",
    "distances = []\n",
    "K = range(2,20)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, init='k-means++')\n",
    "    km = km.fit(X)\n",
    "    labels = km.labels_\n",
    "    distances.append(km.inertia_)\n",
    "    sil.append(silhouette_score(X, labels, metric = 'euclidean'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use elbow and silhouette methods to determine optimal k\n",
    "\n",
    "Looking at the plots, there is no clear elbow, but we can see the slope slightly changing at $k=7$. The silhouette plot further confirms this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(K, distances, 'bo-')\n",
    "plt.tick_params(direction=\"in\")\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of square distances')\n",
    "plt.title('Elbow Method')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(K, sil, 'bo-')\n",
    "plt.tick_params(direction=\"in\")\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get clusters for $k=7$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_k = 7\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=300, n_init=20)\n",
    "model.fit(X)\n",
    "\n",
    "\n",
    "prediction = model.predict(X)\n",
    "df[\"cluster\"] = prediction\n",
    "print(df[\"cluster\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the top terms of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    print(df[df[\"cluster\"]==i][\"key\"].value_counts())\n",
    "    for ind in order_centroids[i, :15]:\n",
    "        print(' %s' % terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
